{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Number of battery image:178\n",
      "Number of camera_battery image:179\n",
      "Number of cardboard image:402\n",
      "Number of clothes image:332\n",
      "Number of contaminated_plastic image:399\n",
      "Number of glass image:459\n",
      "Number of human image:448\n",
      "Number of keyboard image:364\n",
      "Number of metal image:342\n",
      "Number of mouse image:328\n",
      "Number of pak image:246\n",
      "Number of pants image:258\n",
      "Number of paper image:417\n",
      "Number of pen image:390\n",
      "Number of phone image:508\n",
      "Number of plastic image:405\n",
      "Number of wrapper image:340\n",
      "Total number of image: 5995\n"
     ]
    }
   ],
   "source": [
    "path = \"../img/train\"\n",
    "class_names = ['battery','camera_battery', 'cardboard','clothes','contaminated_plastic','glass', 'human', 'keyboard','metal','mouse','pak','pants','paper', 'pen','phone', 'plastic','wrapper']\n",
    "class_num = len(class_names)\n",
    "print(class_num)\n",
    "total = 0\n",
    "\n",
    "for name in class_names:\n",
    "    name_path = os.path.join(path, name)\n",
    "    num = len(os.listdir(name_path))\n",
    "    total += num\n",
    "    print(\"Number of \" + name + \" image:\" + str(num))\n",
    "\n",
    "print(\"Total number of image: \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 35\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=45,\n",
    "                                    width_shift_range=.15,\n",
    "                                    height_shift_range=.15,\n",
    "                                    horizontal_flip=True,\n",
    "                                    zoom_range=0.5\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5995 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = data_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                              directory=path,\n",
    "                                              shuffle=True,\n",
    "                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                              class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(class_num, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 161s 4s/step - loss: 2.6264 - acc: 0.1708\n",
      "Epoch 2/35\n",
      "46/46 [==============================] - 137s 3s/step - loss: 2.2432 - acc: 0.2988\n",
      "Epoch 3/35\n",
      "46/46 [==============================] - 148s 3s/step - loss: 2.0212 - acc: 0.3595\n",
      "Epoch 4/35\n",
      "42/46 [==========================>...] - ETA: 19s - loss: 1.9142 - acc: 0.3957"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    data_gen,\n",
    "    steps_per_epoch=total // batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
